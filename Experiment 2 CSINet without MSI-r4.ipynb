{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70834c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Select the GPU index\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import warnings\n",
    "import spacy\n",
    "from scipy.io import savemat\n",
    "from scipy import stats\n",
    "import dill as pickle\n",
    "import thop\n",
    "from torch_challenge_dataset import DeepVerseChallengeLoaderTaskTwo\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75a6c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "onoffdict={'GPS': False, 'CAMERAS': False, 'RADAR': False}\n",
    "reduction = 4\n",
    "batch_size = 200\n",
    "weight_path=f'models/CSINettask2/cr{reduction}/gps{onoffdict[\"GPS\"]}_cam{onoffdict[\"CAMERAS\"]}_rad{onoffdict[\"RADAR\"]}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef315b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036636ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/CSINettask2/cr4/gpsFalse_camFalse_radFalse/'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dae38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(weight_path):\n",
    "    os.makedirs(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a3e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4146014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepVerseChallengeLoaderTaskTwo(csv_path = r'./dataset_train.csv')\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ca6927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c78c6170",
   "metadata": {},
   "source": [
    "# Utils and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e01a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSI_reshape( y, csi_std=2.5e-06, target_std=1):\n",
    "        ry = torch.real(y)\n",
    "        iy= torch.imag(y)\n",
    "        oy=torch.cat([ry,iy],dim=1)\n",
    "        #scaling\n",
    "        oy=(oy/csi_std)*target_std\n",
    "        return oy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab275daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSI_abs_reshape(y, csi_std=2.8117975e-06, target_std=1.0):\n",
    "    y = torch.abs(y)\n",
    "    y=(y/csi_std)*target_std\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a60031c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing output as neural network doesnot understand complex numbers, without normalization\n",
    "def CSI_complex2real(y):\n",
    "    ry = torch.real(y)\n",
    "    iy= torch.imag(y)\n",
    "    oy=torch.cat([ry,iy],dim=1)\n",
    "    return oy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b783bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_model_parameters(model):\n",
    "    total_param  = []\n",
    "    for p1 in model.parameters():\n",
    "        total_param.append(int(p1.numel()))\n",
    "    return sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c21d6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBN(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, groups=1):\n",
    "        if not isinstance(kernel_size, int):\n",
    "            padding = [(i - 1) // 2 for i in kernel_size]\n",
    "        else:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        super(ConvBN, self).__init__(OrderedDict([\n",
    "            ('conv', nn.Conv2d(in_channels=in_planes,\n",
    "                               out_channels=out_planes,\n",
    "                               kernel_size=kernel_size,\n",
    "                               stride=stride,\n",
    "                               padding=padding,\n",
    "                               groups=groups,\n",
    "                               bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_planes))\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89e3110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.direct_path = nn.Sequential(OrderedDict([\n",
    "            (\"conv_1\", ConvBN(2, 8, kernel_size=3)),\n",
    "            (\"conv_2\", ConvBN(8, 16, kernel_size=3)),\n",
    "            (\"conv_3\", nn.Conv2d(16, 2, kernel_size=3, stride=1, padding=1)),\n",
    "            (\"bn\", nn.BatchNorm2d(2))\n",
    "        ]))\n",
    "        self.identity = nn.Identity()\n",
    "        self.relu = nn.LeakyReLU(negative_slope=0.3, inplace=True)\n",
    "    def forward(self, x):\n",
    "        identity = self.identity(x)\n",
    "        out = self.direct_path(x)\n",
    "        out = self.relu(out + identity)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f70d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class task2Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduction=16):\n",
    "        super(task2Encoder, self).__init__()\n",
    "        self.total_size =8192\n",
    "        n1=int(math.log2(reduction))\n",
    "        self.encoder_convbn = ConvBN(1, 2, kernel_size=3)\n",
    "        self.encoder_fc = nn.Linear(self.total_size, self.total_size // reduction)\n",
    "       \n",
    "        \n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.detach().size()\n",
    "        out = self.encoder_convbn(x.to(torch.float32))\n",
    "        out =  self.encoder_fc(out.view(n, -1))\n",
    "        \n",
    "        return out\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf1fbe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class task2Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, reduction=16):\n",
    "        super(task2Decoder, self).__init__()\n",
    "        self.total_size = 8192\n",
    "        w, h =64, 64\n",
    "        self.reduced_size = self.total_size//reduction\n",
    "        self.decoder_fc = nn.Linear(self.total_size // reduction, self.total_size)\n",
    "        \n",
    "        self.decoder_RefineNet1 = ResBlock()\n",
    "        self.decoder_RefineNet2 = ResBlock()\n",
    "        self.decoder_conv = nn.Conv2d(2, 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.decoder_bn = nn.BatchNorm2d(2)\n",
    "        \n",
    "        \n",
    "        self.decoder_fc2 = nn.Linear(self.total_size, self.total_size//2)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, Hencoded):\n",
    "        bs = Hencoded.size(0)\n",
    "        #combining\n",
    "        out = Hencoded.view(bs, self.reduced_size)\n",
    "        # Generate final output\n",
    "        out = self.decoder_fc(out)\n",
    "        \n",
    "        out = out.view(bs, -1, 64, 64)\n",
    "        out = self.decoder_RefineNet1(out)\n",
    "        out = self.decoder_RefineNet2(out)\n",
    "        out = self.decoder_conv(out)\n",
    "        out = self.sig2(self.decoder_fc2(out.view(bs, -1)))\n",
    "        \n",
    "        return out.view(bs, -1, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46df19e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete task 2 model including encoder, decoder and channel\n",
    "class task2model(nn.Module):\n",
    "    def __init__(self, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.en=task2Encoder(reduction)\n",
    "        \n",
    "        self.de=task2Decoder(reduction)\n",
    "        \n",
    "    \n",
    "   \n",
    "    def forward(self, Hin, device, is_training): \n",
    "        \n",
    "        #Encoder\n",
    "        Hencoded=self.en(Hin)\n",
    "        \n",
    "        \n",
    "        #Decoder   \n",
    "        Hdecoded=self.de(Hencoded)\n",
    "        \n",
    "\n",
    "        return Hdecoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ba50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss\n",
    "\n",
    "#criterion=nn.BCELoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion= nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac6c938",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7cd471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model, test_loader, device, criterion):\n",
    "    num_test_batches = len(test_loader)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mse1 = 0\n",
    "        for b, (X_test, y_test) in enumerate(test_loader):\n",
    "            y_test = y_test.to(device)\n",
    "            Xin = CSI_abs_reshape(X_test[0])\n",
    "            y_pred = model(Xin.to(device), device, is_training=False)\n",
    "            y_test_reshaped = CSI_abs_reshape(y_test)\n",
    "            mse0 = criterion(y_pred, y_test_reshaped) \n",
    "            mse1 += mse0 \n",
    "        \n",
    "    avg_mse = mse1 / num_test_batches\n",
    "    return avg_mse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5399da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    se = stats.sem(data)\n",
    "    h = se * stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return mean, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "585716bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DeepVerseChallengeLoaderTaskTwo(csv_path = r'./dataset_validation.csv')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70a7d594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "h_list = torch.tensor([])\n",
    "for b, (x,h) in enumerate(test_loader):\n",
    "    h = CSI_abs_reshape(h)\n",
    "    h_list = torch.cat([h_list,h])\n",
    "target_loss = torch.mean((torch.abs(h_list) - torch.mean(torch.abs(h_list))) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0501436",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs =20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c83fa7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Improvement Mean Achieved: 21.7871%\n",
      "Percentage Improvement Confidence Interval Achieved: 0.7940%\n",
      "Mean MSE: 0.8727\n",
      "95% Confidence Interval: (0.8638, 0.8815)\n",
      "Margin of Error: 0.0089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_mse_list = []\n",
    "improvement_list = []\n",
    "for _ in range(num_runs):\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "    model = torch.load(weight_path + \"task2.pth\").to(device)\n",
    "    avg_mse = run_test(model, test_loader, device, criterion)\n",
    "    avg_mse_list.append(avg_mse)\n",
    "    improvement = (target_loss.item() - avg_mse) / target_loss.item() * 100\n",
    "    improvement_list.append(improvement)\n",
    "mean_mse, margin_of_error = calculate_confidence_interval(avg_mse_list)\n",
    "improvement_mean, improvement_margin_of_error = calculate_confidence_interval(improvement_list)\n",
    "print(f'Percentage Improvement Mean Achieved: {improvement_mean:.4f}%')\n",
    "print(f'Percentage Improvement Confidence Interval Achieved: {improvement_margin_of_error:.4f}%')\n",
    "print(f\"Mean MSE: {mean_mse:.4f}\")\n",
    "print(f\"95% Confidence Interval: ({mean_mse - margin_of_error:.4f}, {mean_mse + margin_of_error:.4f})\")\n",
    "print(f\"Margin of Error: {margin_of_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7f56f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
